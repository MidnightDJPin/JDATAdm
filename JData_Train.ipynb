{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('uid_train.txt',sep='\\t',header=None)\n",
    "train_df.columns = ['uid','label']\n",
    "\n",
    "train_sms = pd.read_csv('sms_train.txt',sep='\\t',header=None)\n",
    "train_sms.columns = ['uid','opp_num','opp_head','opp_len','start_time','in_out']\n",
    "\n",
    "train_voice = pd.read_csv('voice_train.txt',sep='\\t',header=None)\n",
    "train_voice.columns = ['uid','opp_num','opp_head','opp_len','start_time','end_time','call_type','in_out']\n",
    "\n",
    "train_wa = pd.read_csv('wa_train.txt',sep='\\t',header=None)\n",
    "train_wa.columns = ['uid','wa_name','visit_cnt','visit_dura','up_flow','down_flow','wa_type','date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sms = pd.read_csv('sms_test_b.txt',sep='\\t',header=None)\n",
    "test_sms.columns = ['uid','opp_num','opp_head','opp_len','start_time','in_out']\n",
    "\n",
    "test_voice = pd.read_csv('voice_test_b.txt',sep='\\t',header=None)\n",
    "test_voice.columns = ['uid','opp_num','opp_head','opp_len','start_time','end_time','call_type','in_out']\n",
    "\n",
    "test_wa = pd.read_csv('wa_test_b.txt',sep='\\t',header=None)\n",
    "test_wa.columns = ['uid','wa_name','visit_cnt','visit_dura','up_flow','down_flow','wa_type','date']\n",
    "\n",
    "test_df = pd.DataFrame({'uid':pd.unique(test_wa['uid'])})\n",
    "test_df.to_csv('uid_test_b_v2.txt',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice = pd.concat([train_voice,test_voice],axis=0)\n",
    "sms = pd.concat([train_sms,test_sms],axis=0)\n",
    "wa = pd.concat([train_wa,test_wa],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = train_df\n",
    "test_feature = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_feature = pd.DataFrame()\n",
    "#号码总数\n",
    "gp = sms.groupby('uid')['opp_num']\n",
    "x = gp.apply(lambda x:x.count())\n",
    "sms_feature['uid'] = x.index\n",
    "sms_feature['sms_opp_num_count_all'] = x.values\n",
    "#不同号码的数量\n",
    "gp = sms.groupby('uid')['opp_num']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "sms_feature['sms_opp_num_count_unique'] = x.values\n",
    "\n",
    "#头部\n",
    "gp = sms.groupby('uid')['opp_head']\n",
    "x = gp.apply(lambda x:x.max())\n",
    "sms_feature['sms_opp_head_max'] = x.values\n",
    "gp = sms.groupby('uid')['opp_head']\n",
    "x = gp.apply(lambda x:x.min())\n",
    "sms_feature['sms_opp_head_min'] = x.values\n",
    "gp = sms.groupby('uid')['opp_head']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "sms_feature['sms_opp_head_mean'] = x.values\n",
    "\n",
    "# ###\n",
    "gp = sms.groupby('uid')['opp_head']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "sms_feature['sms_opp_head_unique'] = x.values\n",
    "#  ###\n",
    "\n",
    "#号码长度\n",
    "gp = sms.groupby('uid')['opp_len']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "sms_feature['sms_opp_len_mean'] = x.values\n",
    "gp = sms.groupby('uid')['opp_len']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "sms_feature['sms_opp_len_sum'] = x.values\n",
    "gp = sms.groupby('uid')['opp_len']\n",
    "x = gp.apply(lambda x:x.max())\n",
    "sms_feature['sms_opp_len_max'] = x.values\n",
    "# gp = sms.groupby('uid')['opp_len']\n",
    "# x = gp.apply(lambda x:x.min())\n",
    "# sms_feature['sms_opp_len_min'] = x.values\n",
    "###\n",
    "# gp = sms.groupby('uid')['opp_len']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# sms_feature['sms_opp_len_unique'] = x.values\n",
    "# ###\n",
    "\n",
    "#短信发生时间\n",
    "gp = sms.groupby('uid')['start_time']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "sms_feature['sms_start_time_mean'] = x.values\n",
    "\n",
    "#打入/打出的号码数量\n",
    "gp = sms.groupby(['uid','in_out'])['opp_num']\n",
    "x = gp.apply(lambda x:x.count())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "sms_feature['sms_opp_num_count_out'] = x['0']\n",
    "sms_feature['sms_opp_num_count_in'] = x['1']\n",
    "gp = sms.groupby(['uid','in_out'])['opp_num']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "sms_feature['sms_opp_num_unique_out'] = x['0']\n",
    "sms_feature['sms_opp_num_unique_in'] = x['1']\n",
    "#打入/打出号码长度均值\n",
    "gp = sms.groupby(['uid','in_out'])['opp_len']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "sms_feature['sms_opp_len_mean_out'] = x['0']\n",
    "sms_feature['sms_opp_len_mean_in'] = x['1']\n",
    "# ###\n",
    "# gp = sms.groupby(['uid','in_out'])['opp_len']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_len_unique_out'] = x['0']\n",
    "# sms_feature['sms_opp_len_unique_in'] = x['1']\n",
    "# ### \n",
    "#打入/打出头部均值\n",
    "gp = sms.groupby(['uid','in_out'])['opp_head']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "sms_feature['sms_opp_head_mean_out'] = x['0']\n",
    "sms_feature['sms_opp_head_mean_in'] = x['1']\n",
    "gp = sms.groupby(['uid','in_out'])['opp_head']\n",
    "x = gp.apply(lambda x:x.max())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "sms_feature['sms_opp_head_max_out'] = x['0']\n",
    "sms_feature['sms_opp_head_max_in'] = x['1']\n",
    "gp = sms.groupby(['uid','in_out'])['opp_head']\n",
    "x = gp.apply(lambda x:x.min())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "sms_feature['sms_opp_head_min_out'] = x['0']\n",
    "sms_feature['sms_opp_head_min_in'] = x['1']\n",
    "\n",
    "###\n",
    "# gp = sms.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_head_unique_out'] = x['0']\n",
    "# sms_feature['sms_opp_head_unique_in'] = x['1']\n",
    "# ###\n",
    "\n",
    "#打入/打出发生时间均值\n",
    "gp = sms.groupby(['uid','in_out'])['start_time']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "sms_feature['sms_start_time_mean_out'] = x['0']\n",
    "sms_feature['sms_start_time_mean_in'] = x['1']\n",
    "\n",
    "sms['date'] = sms['start_time'] / 1000000\n",
    "sms['date'] = sms['date'].astype('int')\n",
    "gp = sms.groupby('uid')['date']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "sms_feature['sms_date_cnt'] = x.values\n",
    "\n",
    "gp = sms.groupby(['uid','in_out'])['date']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "sms_feature['sms_date_mean_out'] = x['0']\n",
    "sms_feature['sms_date_mean_in'] = x['1']\n",
    "gp = sms.groupby(['uid','in_out'])['date']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "sms_feature['sms_date_cnt_out'] = x['0']\n",
    "sms_feature['sms_date_cnt_in'] = x['1']\n",
    "\n",
    "sms_feature['sms_callcnt_perday'] = sms_feature['sms_opp_num_count_all'] / sms_feature['sms_date_cnt']\n",
    "sms_feature['sms_calluniqueout_perday'] = sms_feature['sms_opp_num_unique_out'] / sms_feature['sms_date_cnt_out']\n",
    "sms_feature['sms_calluniquein_perday'] = sms_feature['sms_opp_num_unique_in'] / sms_feature['sms_date_cnt_in']\n",
    "sms_feature['sms_len_perday'] = sms_feature['sms_opp_len_sum'] / sms_feature['sms_date_cnt']\n",
    "\n",
    "# #################\n",
    "sms_feature['sms_head_unique_perday'] = sms_feature['sms_opp_head_unique'] / sms_feature['sms_date_cnt']\n",
    "sms_feature['sms_callunique_perday'] = sms_feature['sms_opp_num_count_unique'] / sms_feature['sms_date_cnt']\n",
    "# ####################################\n",
    "sms_feature['sms_calluniquecntout_perday'] = sms_feature['sms_opp_num_count_out'] / sms_feature['sms_date_cnt_out']\n",
    "sms_feature['sms_calluniquecntin_perday'] = sms_feature['sms_opp_num_count_in'] / sms_feature['sms_date_cnt_in']\n",
    "sms_feature['sms_calluniquemeanout_perday'] = sms_feature['sms_opp_num_count_out'] / sms_feature['sms_date_mean_out']\n",
    "sms_feature['sms_calluniquemeanin_perday'] = sms_feature['sms_opp_num_count_in'] / sms_feature['sms_date_mean_in']\n",
    "sms_feature['sms_calluniqueout_mean_perday'] = sms_feature['sms_opp_num_unique_out'] / sms_feature['sms_date_mean_out']\n",
    "sms_feature['sms_calluniquein_mean_perday'] = sms_feature['sms_opp_num_unique_in'] / sms_feature['sms_date_mean_in']\n",
    "# sms_feature['sms_head_unique_out_perday'] = sms_feature['sms_opp_head_unique_out'] / sms_feature['sms_date_cnt_out']\n",
    "# sms_feature['sms_head_unique_in_perday'] = sms_feature['sms_opp_head_unique_in'] / sms_feature['sms_date_cnt_in']\n",
    "# sms_feature['sms_head_unique_mean_out_perday'] = sms_feature['sms_opp_head_unique_out'] / sms_feature['sms_date_mean_out']\n",
    "# sms_feature['sms_head_unique_mean_in_perday'] = sms_feature['sms_opp_head_unique_in'] / sms_feature['sms_date_mean_in']\n",
    "# sms_feature['sms_len_unique_perday'] = sms_feature['sms_opp_len_unique'] / sms_feature['sms_date_cnt']\n",
    "# #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_date1 = pd.DataFrame()\n",
    "# sms_date1 = sms[sms['date']<=9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_date1_feature = pd.DataFrame()\n",
    "# gp = sms_date1.groupby('uid')['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# sms_date1_feature['uid'] = x.index\n",
    "# sms_date1_feature['sms_date1_visit_date_cnt'] = x.values\n",
    "# #打入/打出的号码数量\n",
    "# gp = sms_date1.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_date1_feature['sms_date1_opp_num_count_out'] = x['0']\n",
    "# sms_date1_feature['sms_date1_opp_num_count_in'] = x['1']\n",
    "# gp = sms_date1.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_date1_feature['sms_date1_opp_num_unique_out'] = x['0']\n",
    "# sms_date1_feature['sms_date1_opp_num_unique_in'] = x['1']\n",
    "# #打入/打出号码长度均值\n",
    "# gp = sms_date1.groupby(['uid','in_out'])['opp_len']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_date1_feature['sms_date1_opp_len_mean_out'] = x['0']\n",
    "# sms_date1_feature['sms_date1_opp_len_mean_in'] = x['1']\n",
    "# \n",
    "# #打入/打出头部均值\n",
    "# gp = sms_date1.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_date1_feature['sms_date1_opp_head_mean_out'] = x['0']\n",
    "# sms_date1_feature['sms_date1_opp_head_mean_in'] = x['1']\n",
    "# gp = sms_date1.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_date1_feature['sms_date1_opp_head_unique_out'] = x['0']\n",
    "# sms_date1_feature['sms_date1_opp_head_unique_in'] = x['1']\n",
    "# gp = sms_date1.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.max())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_date1_feature['sms_date1_opp_head_max_out'] = x['0']\n",
    "# sms_date1_feature['sms_date1_opp_head_max_in'] = x['1']\n",
    "# gp = sms_date1.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.min())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_date1_feature['sms_date1_opp_head_min_out'] = x['0']\n",
    "# sms_date1_feature['sms_date1_opp_head_min_in'] = x['1']\n",
    "# #打入/打出发生时间均值\n",
    "# gp = sms_date1.groupby(['uid','in_out'])['start_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_date1_feature['sms_date1_start_time_mean_out'] = x['0']\n",
    "# sms_date1_feature['sms_date1_start_time_mean_in'] = x['1']\n",
    "# gp = sms_date1.groupby(['uid','in_out'])['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_date1_feature['sms_date1_datecnt_out'] = x['0']\n",
    "# sms_date1_feature['sms_date1_datecnt_in'] = x['1']\n",
    "# \n",
    "# sms_date1_feature['sms_calluniqueout_perday'] = sms_date1_feature['sms_date1_opp_num_unique_out'] / sms_date1_feature['sms_date1_datecnt_out']\n",
    "# sms_date1_feature['sms_calluniquein_perday'] = sms_date1_feature['sms_date1_opp_num_unique_in'] / sms_date1_feature['sms_date1_datecnt_in']\n",
    "# sms_date1_feature['sms_calluniqueout_perday'] = sms_date1_feature['sms_date1_opp_num_count_out'] / sms_date1_feature['sms_date1_datecnt_out']\n",
    "# sms_date1_feature['sms_calluniquein_perday'] = sms_date1_feature['sms_date1_opp_num_count_in'] / sms_date1_feature['sms_date1_datecnt_in']\n",
    "# sms_date1_feature['sms_head_unique_out_perday'] = sms_date1_feature['sms_date1_opp_head_unique_out'] / sms_date1_feature['sms_date1_datecnt_out']\n",
    "# sms_date1_feature['sms_head_unique_in_perday'] = sms_date1_feature['sms_date1_opp_head_unique_in'] / sms_date1_feature['sms_date1_datecnt_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature = train_feature.merge(sms_date1_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# train_feature = train_feature.fillna(0)\n",
    "# test_feature = test_feature.merge(sms_date1_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_date2 = pd.DataFrame()\n",
    "# sms_date2 = sms[sms['date']>9]\n",
    "# sms_date2 = sms_date2[sms_date2['date']<=18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_date2_feature = pd.DataFrame()\n",
    "# gp = sms_date2.groupby('uid')['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# sms_date2_feature['uid'] = x.index\n",
    "# sms_date2_feature['sms_date2_visit_date_cnt'] = x.values\n",
    "# #打入/打出的号码数量\n",
    "# gp = sms_date2.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# sms_date2_feature['sms_date2_opp_num_count_out'] = x['0']\n",
    "# sms_date2_feature['sms_date2_opp_num_count_in'] = x['2']\n",
    "# gp = sms_date2.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# sms_date2_feature['sms_date2_opp_num_unique_out'] = x['0']\n",
    "# sms_date2_feature['sms_date2_opp_num_unique_in'] = x['2']\n",
    "# #打入/打出号码长度均值\n",
    "# gp = sms_date2.groupby(['uid','in_out'])['opp_len']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# sms_date2_feature['sms_date2_opp_len_mean_out'] = x['0']\n",
    "# sms_date2_feature['sms_date2_opp_len_mean_in'] = x['2']\n",
    "# \n",
    "# #打入/打出头部均值\n",
    "# gp = sms_date2.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# sms_date2_feature['sms_date2_opp_head_mean_out'] = x['0']\n",
    "# sms_date2_feature['sms_date2_opp_head_mean_in'] = x['2']\n",
    "# gp = sms_date2.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# sms_date2_feature['sms_date2_opp_head_unique_out'] = x['0']\n",
    "# sms_date2_feature['sms_date2_opp_head_unique_in'] = x['2']\n",
    "# gp = sms_date2.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.max())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# sms_date2_feature['sms_date2_opp_head_max_out'] = x['0']\n",
    "# sms_date2_feature['sms_date2_opp_head_max_in'] = x['2']\n",
    "# gp = sms_date2.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.min())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# sms_date2_feature['sms_date2_opp_head_min_out'] = x['0']\n",
    "# sms_date2_feature['sms_date2_opp_head_min_in'] = x['2']\n",
    "# #打入/打出发生时间均值\n",
    "# gp = sms_date2.groupby(['uid','in_out'])['start_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# sms_date2_feature['sms_date2_start_time_mean_out'] = x['0']\n",
    "# sms_date2_feature['sms_date2_start_time_mean_in'] = x['2']\n",
    "# gp = sms_date2.groupby(['uid','in_out'])['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# sms_date2_feature['sms_date2_datecnt_out'] = x['0']\n",
    "# sms_date2_feature['sms_date2_datecnt_in'] = x['2']\n",
    "# \n",
    "# sms_date2_feature['sms_calluniqueout_perday'] = sms_date2_feature['sms_date2_opp_num_unique_out'] / sms_date2_feature['sms_date2_datecnt_out']\n",
    "# sms_date2_feature['sms_calluniquein_perday'] = sms_date2_feature['sms_date2_opp_num_unique_in'] / sms_date2_feature['sms_date2_datecnt_in']\n",
    "# sms_date2_feature['sms_calluniqueout_perday'] = sms_date2_feature['sms_date2_opp_num_count_out'] / sms_date2_feature['sms_date2_datecnt_out']\n",
    "# sms_date2_feature['sms_calluniquein_perday'] = sms_date2_feature['sms_date2_opp_num_count_in'] / sms_date2_feature['sms_date2_datecnt_in']\n",
    "# sms_date2_feature['sms_head_unique_out_perday'] = sms_date2_feature['sms_date2_opp_head_unique_out'] / sms_date2_feature['sms_date2_datecnt_out']\n",
    "# sms_date2_feature['sms_head_unique_in_perday'] = sms_date2_feature['sms_date2_opp_head_unique_in'] / sms_date2_feature['sms_date2_datecnt_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature = train_feature.merge(sms_date2_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# train_feature = train_feature.fillna(0)\n",
    "# test_feature = test_feature.merge(sms_date2_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_date3 = pd.DataFrame()\n",
    "# sms_date3 = sms[sms['date']>18]\n",
    "# sms_date3 = sms_date3[sms_date3['date']<=27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_date3_feature = pd.DataFrame()\n",
    "# gp = sms_date3.groupby('uid')['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# sms_date3_feature['uid'] = x.index\n",
    "# sms_date3_feature['sms_date3_visit_date_cnt'] = x.values\n",
    "# #打入/打出的号码数量\n",
    "# gp = sms_date3.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# sms_date3_feature['sms_date3_opp_num_count_out'] = x['0']\n",
    "# sms_date3_feature['sms_date3_opp_num_count_in'] = x['3']\n",
    "# gp = sms_date3.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# sms_date3_feature['sms_date3_opp_num_unique_out'] = x['0']\n",
    "# sms_date3_feature['sms_date3_opp_num_unique_in'] = x['3']\n",
    "# #打入/打出号码长度均值\n",
    "# gp = sms_date3.groupby(['uid','in_out'])['opp_len']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# sms_date3_feature['sms_date3_opp_len_mean_out'] = x['0']\n",
    "# sms_date3_feature['sms_date3_opp_len_mean_in'] = x['3']\n",
    "# \n",
    "# #打入/打出头部均值\n",
    "# gp = sms_date3.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# sms_date3_feature['sms_date3_opp_head_mean_out'] = x['0']\n",
    "# sms_date3_feature['sms_date3_opp_head_mean_in'] = x['3']\n",
    "# gp = sms_date3.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# sms_date3_feature['sms_date3_opp_head_unique_out'] = x['0']\n",
    "# sms_date3_feature['sms_date3_opp_head_unique_in'] = x['3']\n",
    "# gp = sms_date3.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.max())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# sms_date3_feature['sms_date3_opp_head_max_out'] = x['0']\n",
    "# sms_date3_feature['sms_date3_opp_head_max_in'] = x['3']\n",
    "# gp = sms_date3.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.min())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# sms_date3_feature['sms_date3_opp_head_min_out'] = x['0']\n",
    "# sms_date3_feature['sms_date3_opp_head_min_in'] = x['3']\n",
    "# #打入/打出发生时间均值\n",
    "# gp = sms_date3.groupby(['uid','in_out'])['start_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# sms_date3_feature['sms_date3_start_time_mean_out'] = x['0']\n",
    "# sms_date3_feature['sms_date3_start_time_mean_in'] = x['3']\n",
    "# gp = sms_date3.groupby(['uid','in_out'])['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# sms_date3_feature['sms_date3_datecnt_out'] = x['0']\n",
    "# sms_date3_feature['sms_date3_datecnt_in'] = x['3']\n",
    "# \n",
    "# sms_date3_feature['sms_calluniqueout_perday'] = sms_date3_feature['sms_date3_opp_num_unique_out'] / sms_date3_feature['sms_date3_datecnt_out']\n",
    "# sms_date3_feature['sms_calluniquein_perday'] = sms_date3_feature['sms_date3_opp_num_unique_in'] / sms_date3_feature['sms_date3_datecnt_in']\n",
    "# sms_date3_feature['sms_calluniqueout_perday'] = sms_date3_feature['sms_date3_opp_num_count_out'] / sms_date3_feature['sms_date3_datecnt_out']\n",
    "# sms_date3_feature['sms_calluniquein_perday'] = sms_date3_feature['sms_date3_opp_num_count_in'] / sms_date3_feature['sms_date3_datecnt_in']\n",
    "# sms_date3_feature['sms_head_unique_out_perday'] = sms_date3_feature['sms_date3_opp_head_unique_out'] / sms_date3_feature['sms_date3_datecnt_out']\n",
    "# sms_date3_feature['sms_head_unique_in_perday'] = sms_date3_feature['sms_date3_opp_head_unique_in'] / sms_date3_feature['sms_date3_datecnt_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature = train_feature.merge(sms_date3_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# train_feature = train_feature.fillna(0)\n",
    "# test_feature = test_feature.merge(sms_date3_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_date4 = pd.DataFrame()\n",
    "# sms_date4 = sms[sms['date']>27]\n",
    "# sms_date4 = sms_date4[sms_date4['date']<=36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_date4_feature = pd.DataFrame()\n",
    "# gp = sms_date4.groupby('uid')['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# sms_date4_feature['uid'] = x.index\n",
    "# sms_date4_feature['sms_date4_visit_date_cnt'] = x.values\n",
    "# #打入/打出的号码数量\n",
    "# gp = sms_date4.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# sms_date4_feature['sms_date4_opp_num_count_out'] = x['0']\n",
    "# sms_date4_feature['sms_date4_opp_num_count_in'] = x['4']\n",
    "# gp = sms_date4.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# sms_date4_feature['sms_date4_opp_num_unique_out'] = x['0']\n",
    "# sms_date4_feature['sms_date4_opp_num_unique_in'] = x['4']\n",
    "# #打入/打出号码长度均值\n",
    "# gp = sms_date4.groupby(['uid','in_out'])['opp_len']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# sms_date4_feature['sms_date4_opp_len_mean_out'] = x['0']\n",
    "# sms_date4_feature['sms_date4_opp_len_mean_in'] = x['4']\n",
    "# \n",
    "# #打入/打出头部均值\n",
    "# gp = sms_date4.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# sms_date4_feature['sms_date4_opp_head_mean_out'] = x['0']\n",
    "# sms_date4_feature['sms_date4_opp_head_mean_in'] = x['4']\n",
    "# gp = sms_date4.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# sms_date4_feature['sms_date4_opp_head_unique_out'] = x['0']\n",
    "# sms_date4_feature['sms_date4_opp_head_unique_in'] = x['4']\n",
    "# gp = sms_date4.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.max())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# sms_date4_feature['sms_date4_opp_head_max_out'] = x['0']\n",
    "# sms_date4_feature['sms_date4_opp_head_max_in'] = x['4']\n",
    "# gp = sms_date4.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.min())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# sms_date4_feature['sms_date4_opp_head_min_out'] = x['0']\n",
    "# sms_date4_feature['sms_date4_opp_head_min_in'] = x['4']\n",
    "# #打入/打出发生时间均值\n",
    "# gp = sms_date4.groupby(['uid','in_out'])['start_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# sms_date4_feature['sms_date4_start_time_mean_out'] = x['0']\n",
    "# sms_date4_feature['sms_date4_start_time_mean_in'] = x['4']\n",
    "# gp = sms_date4.groupby(['uid','in_out'])['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# sms_date4_feature['sms_date4_datecnt_out'] = x['0']\n",
    "# sms_date4_feature['sms_date4_datecnt_in'] = x['4']\n",
    "# \n",
    "# sms_date4_feature['sms_calluniqueout_perday'] = sms_date4_feature['sms_date4_opp_num_unique_out'] / sms_date4_feature['sms_date4_datecnt_out']\n",
    "# sms_date4_feature['sms_calluniquein_perday'] = sms_date4_feature['sms_date4_opp_num_unique_in'] / sms_date4_feature['sms_date4_datecnt_in']\n",
    "# sms_date4_feature['sms_calluniqueout_perday'] = sms_date4_feature['sms_date4_opp_num_count_out'] / sms_date4_feature['sms_date4_datecnt_out']\n",
    "# sms_date4_feature['sms_calluniquein_perday'] = sms_date4_feature['sms_date4_opp_num_count_in'] / sms_date4_feature['sms_date4_datecnt_in']\n",
    "# sms_date4_feature['sms_head_unique_out_perday'] = sms_date4_feature['sms_date4_opp_head_unique_out'] / sms_date4_feature['sms_date4_datecnt_out']\n",
    "# sms_date4_feature['sms_head_unique_in_perday'] = sms_date4_feature['sms_date4_opp_head_unique_in'] / sms_date4_feature['sms_date4_datecnt_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature = train_feature.merge(sms_date4_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# train_feature = train_feature.fillna(0)\n",
    "# test_feature = test_feature.merge(sms_date4_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_date5 = pd.DataFrame()\n",
    "# sms_date5 = sms[sms['date']>36]\n",
    "# sms_date5 = sms_date4[sms_date4['date']<=45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sms_date5_feature = pd.DataFrame()\n",
    "# gp = sms_date5.groupby('uid')['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# sms_date5_feature['uid'] = x.index\n",
    "# sms_date5_feature['sms_date5_visit_date_cnt'] = x.values\n",
    "# #打入/打出的号码数量\n",
    "# gp = sms_date5.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# sms_date5_feature['sms_date5_opp_num_count_out'] = x['0']\n",
    "# sms_date5_feature['sms_date5_opp_num_count_in'] = x['5']\n",
    "# gp = sms_date5.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# sms_date5_feature['sms_date5_opp_num_unique_out'] = x['0']\n",
    "# sms_date5_feature['sms_date5_opp_num_unique_in'] = x['5']\n",
    "# #打入/打出号码长度均值\n",
    "# gp = sms_date5.groupby(['uid','in_out'])['opp_len']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# sms_date5_feature['sms_date5_opp_len_mean_out'] = x['0']\n",
    "# sms_date5_feature['sms_date5_opp_len_mean_in'] = x['5']\n",
    "# \n",
    "# #打入/打出头部均值\n",
    "# gp = sms_date5.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# sms_date5_feature['sms_date5_opp_head_mean_out'] = x['0']\n",
    "# sms_date5_feature['sms_date5_opp_head_mean_in'] = x['5']\n",
    "# gp = sms_date5.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# sms_date5_feature['sms_date5_opp_head_unique_out'] = x['0']\n",
    "# sms_date5_feature['sms_date5_opp_head_unique_in'] = x['5']\n",
    "# gp = sms_date5.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.max())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# sms_date5_feature['sms_date5_opp_head_max_out'] = x['0']\n",
    "# sms_date5_feature['sms_date5_opp_head_max_in'] = x['5']\n",
    "# gp = sms_date5.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.min())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# sms_date5_feature['sms_date5_opp_head_min_out'] = x['0']\n",
    "# sms_date5_feature['sms_date5_opp_head_min_in'] = x['5']\n",
    "# #打入/打出发生时间均值\n",
    "# gp = sms_date5.groupby(['uid','in_out'])['start_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# sms_date5_feature['sms_date5_start_time_mean_out'] = x['0']\n",
    "# sms_date5_feature['sms_date5_start_time_mean_in'] = x['5']\n",
    "# gp = sms_date5.groupby(['uid','in_out'])['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# sms_date5_feature['sms_date5_datecnt_out'] = x['0']\n",
    "# sms_date5_feature['sms_date5_datecnt_in'] = x['5']\n",
    "# \n",
    "# sms_date5_feature['sms_calluniqueout_perday'] = sms_date5_feature['sms_date5_opp_num_unique_out'] / sms_date5_feature['sms_date5_datecnt_out']\n",
    "# sms_date5_feature['sms_calluniquein_perday'] = sms_date5_feature['sms_date5_opp_num_unique_in'] / sms_date5_feature['sms_date5_datecnt_in']\n",
    "# sms_date5_feature['sms_calluniqueout_perday'] = sms_date5_feature['sms_date5_opp_num_count_out'] / sms_date5_feature['sms_date5_datecnt_out']\n",
    "# sms_date5_feature['sms_calluniquein_perday'] = sms_date5_feature['sms_date5_opp_num_count_in'] / sms_date5_feature['sms_date5_datecnt_in']\n",
    "# sms_date5_feature['sms_head_unique_out_perday'] = sms_date5_feature['sms_date5_opp_head_unique_out'] / sms_date5_feature['sms_date5_datecnt_out']\n",
    "# sms_date5_feature['sms_head_unique_in_perday'] = sms_date5_feature['sms_date5_opp_head_unique_in'] / sms_date5_feature['sms_date5_datecnt_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature = train_feature.merge(sms_date5_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# train_feature = train_feature.fillna(0)\n",
    "# test_feature = test_feature.merge(sms_date5_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opp_len_13 = pd.DataFrame()\n",
    "# opp_len_13 = sms[sms['opp_len']==13]\n",
    "# gp = opp_len_13.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_num_13_cnt0'] = x['0']\n",
    "# sms_feature['sms_opp_num_13_cnt1'] = x['1']\n",
    "# gp = opp_len_13.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_num_13_unique0'] = x['0']\n",
    "# sms_feature['sms_opp_num_13_unique1'] = x['1']\n",
    "# gp = opp_len_13.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_head_13_unique0'] = x['0']\n",
    "# sms_feature['sms_opp_head_13_unique1'] = x['1']\n",
    "# gp = opp_len_13.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_head_13_mean0'] = x['0']\n",
    "# sms_feature['sms_opp_head_13_mean1'] = x['1']\n",
    "# gp = opp_len_13.groupby(['uid','in_out'])['start_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_start_time_13_mean0'] = x['0']\n",
    "# sms_feature['sms_start_time_13_mean1'] = x['1']\n",
    "# gp = opp_len_13.groupby(['uid','in_out'])['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_date_13_cnt0'] = x['0']\n",
    "# sms_feature['sms_date_13_cnt1'] = x['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opp_len_11 = pd.DataFrame()\n",
    "# opp_len_11 = sms[sms['opp_len']==11]\n",
    "# gp = opp_len_11.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_num_11_cnt0'] = x['0']\n",
    "# sms_feature['sms_opp_num_11_cnt1'] = x['1']\n",
    "# gp = opp_len_11.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_num_11_unique0'] = x['0']\n",
    "# sms_feature['sms_opp_num_11_unique1'] = x['1']\n",
    "# gp = opp_len_11.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_head_11_unique0'] = x['0']\n",
    "# sms_feature['sms_opp_head_11_unique1'] = x['1']\n",
    "# gp = opp_len_11.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_head_11_mean0'] = x['0']\n",
    "# sms_feature['sms_opp_head_11_mean1'] = x['1']\n",
    "# gp = opp_len_11.groupby(['uid','in_out'])['start_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_start_time_11_mean0'] = x['0']\n",
    "# sms_feature['sms_start_time_11_mean1'] = x['1']\n",
    "# gp = opp_len_11.groupby(['uid','in_out'])['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_date_11_cnt0'] = x['0']\n",
    "# sms_feature['sms_date_11_cnt1'] = x['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opp_len_12 = pd.DataFrame()\n",
    "# opp_len_12 = sms[sms['opp_len']==12]\n",
    "# gp = opp_len_12.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_num_12_cnt0'] = x['0']\n",
    "# sms_feature['sms_opp_num_12_cnt1'] = x['1']\n",
    "# gp = opp_len_12.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_num_12_unique0'] = x['0']\n",
    "# sms_feature['sms_opp_num_12_unique1'] = x['1']\n",
    "# gp = opp_len_12.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_head_12_unique0'] = x['0']\n",
    "# sms_feature['sms_opp_head_12_unique1'] = x['1']\n",
    "# gp = opp_len_12.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_opp_head_12_mean0'] = x['0']\n",
    "# sms_feature['sms_opp_head_12_mean1'] = x['1']\n",
    "# gp = opp_len_12.groupby(['uid','in_out'])['start_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_start_time_12_mean0'] = x['0']\n",
    "# sms_feature['sms_start_time_12_mean1'] = x['1']\n",
    "# gp = opp_len_12.groupby(['uid','in_out'])['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# sms_feature['sms_date_12_cnt0'] = x['0']\n",
    "# sms_feature['sms_date_12_cnt1'] = x['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = train_feature.merge(sms_feature,on='uid',how='left').reset_index(drop=True)\n",
    "train_feature = train_feature.fillna(0)\n",
    "test_feature = test_feature.merge(sms_feature,on='uid',how='left').reset_index(drop=True)\n",
    "test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_to_int(x):\n",
    "    default = '000'\n",
    "    if x=='DDD':\n",
    "        return default\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_feature = pd.DataFrame()\n",
    "#总的通话数目\n",
    "gp = voice.groupby('uid')['opp_num']\n",
    "x = gp.apply(lambda x:x.count())\n",
    "voice_feature['uid'] = x.index\n",
    "voice_feature['voice_opp_count_all'] = x.values\n",
    "#通话号码的数量\n",
    "gp = voice.groupby('uid')['opp_num']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "voice_feature['voice_opp_num_unique'] = x.values\n",
    "\n",
    "#号码长度均值\n",
    "gp = voice.groupby('uid')['opp_len']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "voice_feature['voice_opp_len_mean'] = x.values\n",
    "gp = voice.groupby('uid')['opp_len']\n",
    "x = gp.apply(lambda x:x.max())\n",
    "voice_feature['voice_opp_len_max'] = x.values\n",
    "\n",
    "###\n",
    "gp = voice.groupby('uid')['opp_len']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "voice_feature['voice_opp_len_unique'] = x.values\n",
    "###\n",
    "\n",
    "# 多少种头部的\n",
    "gp = voice.groupby('uid')['opp_head']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "voice_feature['voice_opp_head_unique'] = x.values\n",
    "\n",
    "#出现最大的头部\n",
    "voice['opp_head'] = voice['opp_head'].apply(lambda x:head_to_int(x))\n",
    "voice['opp_head'] = voice['opp_head'].astype('int')\n",
    "gp = voice.groupby('uid')['opp_head']\n",
    "x = gp.apply(lambda x:x.max())\n",
    "voice_feature['voice_opp_head_max'] = x.values\n",
    "\n",
    "voice['opp_head'] = voice['opp_head'].apply(lambda x:head_to_int(x))\n",
    "voice['opp_head'] = voice['opp_head'].astype('int')\n",
    "gp = voice.groupby('uid')['opp_head']\n",
    "x = gp.apply(lambda x:x.min())\n",
    "voice_feature['voice_opp_head_min'] = x.values\n",
    "\n",
    "#出现头部的均值\n",
    "voice['opp_head'] = voice['opp_head'].apply(lambda x:head_to_int(x))\n",
    "voice['opp_head'] = voice['opp_head'].astype('int')\n",
    "gp = voice.groupby('uid')['opp_head']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "voice_feature['voice_opp_head_mean'] = x.values\n",
    "\n",
    "#通话时长均值/最大值/最小值\n",
    "# voice['start_time'] = pd.to_datetime(voice['start_time'])\n",
    "# voice['end_time'] = pd.to_datetime(voice['end_time'])\n",
    "voice['voice_time'] = voice['end_time'] - voice['start_time']\n",
    "gp = voice.groupby('uid')['voice_time']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "voice_feature['voice_time_mean'] = x.values\n",
    "gp = voice.groupby('uid')['voice_time']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "voice_feature['voice_time_sum'] = x.values\n",
    "gp = voice.groupby('uid')['voice_time']\n",
    "x = gp.apply(lambda x:x.max())\n",
    "voice_feature['voice_time_max'] = x.values\n",
    "gp = voice.groupby('uid')['voice_time']\n",
    "x = gp.apply(lambda x:x.min())\n",
    "voice_feature['voice_time_min'] = x.values\n",
    "gp = voice.groupby('uid')['voice_time']\n",
    "x = gp.apply(lambda x:x.median())\n",
    "voice_feature['voice_time_median'] = x.values\n",
    "gp = voice.groupby('uid')['voice_time']\n",
    "x = gp.apply(lambda x:x.std())\n",
    "voice_feature['voice_time_std'] = x.values\n",
    "\n",
    "#打出多少号码，打入多少号码\n",
    "gp = voice.groupby(['uid','in_out'])['opp_num']\n",
    "x = gp.apply(lambda x:x.count())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "voice_feature['voice_opp_count_out'] = x['0']\n",
    "voice_feature['voice_opp_count_in'] = x['1']\n",
    "#打入多少种号码，打出多少种号码\n",
    "gp = voice.groupby(['uid','in_out'])['opp_num']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "voice_feature['voice_opp_unique_out'] = x['0']\n",
    "voice_feature['voice_opp_unique_in'] = x['1']\n",
    "#打入号码的平均长度，打出号码的平均长度\n",
    "gp = voice.groupby(['uid','in_out'])['opp_len']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "voice_feature['voice_len_mean_out'] = x['0']\n",
    "voice_feature['voice_len_mean_in'] = x['1']\n",
    "# \n",
    "gp = voice.groupby(['uid','in_out'])['opp_len']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "voice_feature['voice_len_sum_out'] = x['0']\n",
    "voice_feature['voice_len_sum_in'] = x['1']\n",
    "gp = voice.groupby(['uid','in_out'])['opp_len']\n",
    "x = gp.apply(lambda x:x.max())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "voice_feature['voice_len_max_out'] = x['0']\n",
    "voice_feature['voice_len_max_in'] = x['1']\n",
    "#打入多少种头部，打出多少种头部\n",
    "gp = voice.groupby(['uid','in_out'])['opp_head']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "voice_feature['voice_head_unique_out'] = x['0']\n",
    "voice_feature['voice_head_unique_in'] = x['1']\n",
    "#打入/打出头部均值\n",
    "gp = voice.groupby(['uid','in_out'])['opp_head']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "voice_feature['voice_head_mean_out'] = x['0']\n",
    "voice_feature['voice_head_mean_in'] = x['1']\n",
    "#打入的平均开始时间，打出的平均开始时间\n",
    "gp = voice.groupby(['uid','in_out'])['start_time']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "voice_feature['voice_start_mean_out'] = x['0']\n",
    "voice_feature['voice_start_mean_in'] = x['1']\n",
    "#打入的平均时长，打出的平均时长\n",
    "gp = voice.groupby(['uid','in_out'])['voice_time']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "voice_feature['voice_time_mean_out'] = x['0']\n",
    "voice_feature['voice_time_mean_in'] = x['1']\n",
    "gp = voice.groupby(['uid','in_out'])['voice_time']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "voice_feature['voice_time_sum_out'] = x['0']\n",
    "voice_feature['voice_time_sum_in'] = x['1']\n",
    "\n",
    "voice['date'] = voice['start_time']/1000000\n",
    "voice['date'] = voice['date'].astype('int')\n",
    "gp = voice.groupby('uid')['date']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "voice_feature['voice_date_cnt'] = x.values\n",
    "\n",
    "gp = voice.groupby(['uid','in_out'])['date']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "voice_feature['voice_date_mean_out'] = x['0']\n",
    "voice_feature['voice_date_mean_in'] = x['1']\n",
    "gp = voice.groupby(['uid','in_out'])['date']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "voice_feature['voice_date_cnt_out'] = x['0']\n",
    "voice_feature['voice_date_cnt_in'] = x['1']\n",
    "\n",
    "#不同类型的通话数量\n",
    "gp = voice.groupby(['uid','call_type'])['opp_num']\n",
    "x = gp.apply(lambda x:x.count())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['1','2','3','4','5']\n",
    "voice_feature['voice_num_cnt_type1'] = x['1']\n",
    "voice_feature['voice_num_cnt_type2'] = x['2']\n",
    "voice_feature['voice_num_cnt_type3'] = x['3']\n",
    "gp = voice.groupby(['uid','call_type'])['date']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['1','2','3','4','5']\n",
    "voice_feature['voice_date_count_type1'] = x['1']\n",
    "voice_feature['voice_date_count_type2'] = x['2']\n",
    "voice_feature['voice_date_count_type3'] = x['3']\n",
    "gp = voice.groupby(['uid','call_type'])['date']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['1','2','3','4','5']\n",
    "voice_feature['voice_date_mean_type1'] = x['1']\n",
    "voice_feature['voice_date_mean_type2'] = x['2']\n",
    "voice_feature['voice_date_mean_type3'] = x['3']\n",
    "#不同类型号码长度均值\n",
    "gp = voice.groupby(['uid','call_type'])['opp_len']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['1','2','3','4','5']\n",
    "voice_feature['voice_len_mean_type1'] = x['1']\n",
    "# voice_feature['voice_len_mean_type2'] = x['2']\n",
    "# voice_feature['voice_len_mean_type3'] = x['3']\n",
    "#不同类型的头部均值\n",
    "gp = voice.groupby(['uid','call_type'])['opp_head']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['1','2','3','4','5']\n",
    "voice_feature['voice_head_mean_type1'] = x['1']\n",
    "voice_feature['voice_head_mean_type2'] = x['2']\n",
    "voice_feature['voice_head_mean_type3'] = x['3']\n",
    "# \n",
    "gp = voice.groupby(['uid','call_type'])['opp_head']\n",
    "x = gp.apply(lambda x:x.max())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['1','2','3','4','5']\n",
    "voice_feature['voice_head_max_type1'] = x['1']\n",
    "voice_feature['voice_head_max_type2'] = x['2']\n",
    "voice_feature['voice_head_max_type3'] = x['3']\n",
    "#不同类型的开始时间均值\n",
    "gp = voice.groupby(['uid','call_type'])['voice_time']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['1','2','3','4','5']\n",
    "voice_feature['voice_time_mean_type1'] = x['1']\n",
    "voice_feature['voice_time_mean_type2'] = x['2']\n",
    "voice_feature['voice_time_mean_type3'] = x['3']\n",
    "gp = voice.groupby(['uid','call_type'])['voice_time']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['1','2','3','4','5']\n",
    "voice_feature['voice_time_sum_type1'] = x['1']\n",
    "voice_feature['voice_time_sum_type2'] = x['2']\n",
    "voice_feature['voice_time_sum_type3'] = x['3']\n",
    "\n",
    "\n",
    "voice_feature ['voice_headout_perday'] = voice_feature['voice_head_unique_out'] / voice_feature['voice_date_cnt_out']\n",
    "voice_feature['voice_headin_perday'] = voice_feature['voice_head_unique_in'] / voice_feature['voice_date_cnt_in']\n",
    "voice_feature ['voice_timeoutsum_percall'] = voice_feature['voice_opp_count_out'] / voice_feature['voice_time_sum_out']\n",
    "voice_feature['voice_timeinsum_percall'] = voice_feature['voice_opp_count_in'] / voice_feature['voice_time_sum_in']\n",
    "voice_feature ['voice_timeoutmean_percall'] = voice_feature['voice_opp_unique_out'] / voice_feature['voice_time_mean_out']\n",
    "voice_feature['voice_timeinmean_percall'] = voice_feature['voice_opp_unique_in'] / voice_feature['voice_time_mean_in']\n",
    "voice_feature['voice_timesum_peruniquecall'] = voice_feature['voice_opp_num_unique'] / voice_feature['voice_time_sum']\n",
    "voice_feature['voice_cnt_peruniquecall'] = voice_feature['voice_opp_num_unique'] / voice_feature['voice_date_cnt']\n",
    "voice_feature ['voice_headoutunique_perday'] = voice_feature['voice_head_unique_out'] / voice_feature['voice_date_mean_out']\n",
    "voice_feature['voice_headinunique_perday'] = voice_feature['voice_head_unique_in'] / voice_feature['voice_date_mean_in']\n",
    "# ###############################\n",
    "voice_feature['voice_head_peruniquecall'] = voice_feature['voice_opp_head_unique'] / voice_feature['voice_date_cnt']\n",
    "voice_feature['voice_time1mean_percall'] = voice_feature['voice_num_cnt_type1'] / voice_feature['voice_time_mean_type1']\n",
    "voice_feature['voice_time2mean_percall'] = voice_feature['voice_num_cnt_type2'] / voice_feature['voice_time_mean_type2']\n",
    "voice_feature['voice_time3mean_percall'] = voice_feature['voice_num_cnt_type3'] / voice_feature['voice_time_mean_type3']\n",
    "voice_feature['voice_headmean_peruniquecall'] = voice_feature['voice_opp_head_unique'] / voice_feature['voice_time_mean']\n",
    "voice_feature['voice_len_peruniquecall'] = voice_feature['voice_opp_len_unique'] / voice_feature['voice_date_cnt']\n",
    "voice_feature['voice_lenmean_peruniquecall'] = voice_feature['voice_opp_len_unique'] / voice_feature['voice_time_mean']\n",
    "\n",
    "\n",
    "# #######################\n",
    "voice_feature['voice_timemean_peruniquecall'] = voice_feature['voice_opp_num_unique'] / voice_feature['voice_time_mean']\n",
    "voice_feature ['voice_timeout_percall'] = voice_feature['voice_opp_count_out'] / voice_feature['voice_time_mean_out']\n",
    "voice_feature['voice_timein_percall'] = voice_feature['voice_opp_count_in'] / voice_feature['voice_time_mean_in']\n",
    "voice_feature['voice_time_percall'] = voice_feature['voice_opp_count_all'] / voice_feature['voice_time_sum']\n",
    "###\n",
    "voice_feature['voice_timemean_percall'] = voice_feature['voice_opp_count_all'] / voice_feature['voice_time_mean']\n",
    "###\n",
    "voice_feature['voice_cnt_perday'] = voice_feature['voice_opp_count_all'] / voice_feature['voice_date_cnt']\n",
    "# ###\n",
    "\n",
    "voice_feature ['voice_timeoutunique_percall'] = voice_feature['voice_opp_unique_out'] / voice_feature['voice_time_sum_out']\n",
    "voice_feature['voice_timeinunique_percall'] = voice_feature['voice_opp_unique_in'] / voice_feature['voice_time_sum_in']\n",
    "# ###\n",
    "\n",
    "\n",
    "\n",
    "# ###\n",
    "\n",
    "# ###\n",
    "\n",
    "voice_feature ['voice_cntoutsum_perday'] = voice_feature['voice_opp_count_out'] / voice_feature['voice_date_cnt_out']\n",
    "voice_feature['voice_cntinsum_perday'] = voice_feature['voice_opp_count_in'] / voice_feature['voice_date_cnt_in']\n",
    "\n",
    "# ###\n",
    "voice_feature ['voice_cntoutmean_perday'] = voice_feature['voice_opp_count_out'] / voice_feature['voice_date_mean_out']\n",
    "voice_feature['voice_cntinmean_perday'] = voice_feature['voice_opp_count_in'] / voice_feature['voice_date_mean_in']\n",
    "# ###\n",
    "\n",
    "voice_feature['voice_numcnt1_perday'] = voice_feature['voice_num_cnt_type1'] / voice_feature['voice_date_count_type1']\n",
    "voice_feature['voice_numcnt2_perday'] = voice_feature['voice_num_cnt_type2'] / voice_feature['voice_date_count_type2']\n",
    "voice_feature['voice_numcnt3_perday'] = voice_feature['voice_num_cnt_type3'] / voice_feature['voice_date_count_type3']\n",
    "\n",
    "# ###\n",
    "voice_feature['voice_numcnt1mean_perday'] = voice_feature['voice_num_cnt_type1'] / voice_feature['voice_date_mean_type1']\n",
    "voice_feature['voice_numcnt2mean_perday'] = voice_feature['voice_num_cnt_type2'] / voice_feature['voice_date_mean_type2']\n",
    "voice_feature['voice_numcnt3mean_perday'] = voice_feature['voice_num_cnt_type3'] / voice_feature['voice_date_mean_type3']\n",
    "# ###\n",
    "\n",
    "voice_feature['voice_time1_percall'] = voice_feature['voice_num_cnt_type1'] / voice_feature['voice_time_sum_type1']\n",
    "voice_feature['voice_time2_percall'] = voice_feature['voice_num_cnt_type2'] / voice_feature['voice_time_sum_type2']\n",
    "voice_feature['voice_time3_percall'] = voice_feature['voice_num_cnt_type3'] / voice_feature['voice_time_sum_type3']\n",
    "voice_feature ['voice_timeoutsum_perday'] = voice_feature['voice_time_sum_out'] / voice_feature['voice_date_cnt_out']\n",
    "voice_feature['voice_timeinsum_perday'] = voice_feature['voice_time_sum_in'] / voice_feature['voice_date_cnt_in']\n",
    "\n",
    "# ###\n",
    "voice_feature ['voice_timeoutmean_perday'] = voice_feature['voice_time_sum_out'] / voice_feature['voice_date_mean_out']\n",
    "voice_feature['voice_timeinmean_perday'] = voice_feature['voice_time_sum_in'] / voice_feature['voice_date_mean_in']\n",
    "# ###\n",
    "\n",
    "# ###\n",
    "\n",
    "voice_feature['voice_headsum_peruniquecall'] = voice_feature['voice_opp_head_unique'] / voice_feature['voice_time_sum']\n",
    "voice_feature['voice_lensum_peruniquecall'] = voice_feature['voice_opp_len_unique'] / voice_feature['voice_time_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voice_opp_len_11 = pd.DataFrame()\n",
    "# voice_opp_len_11 = voice[voice['opp_len']==11]\n",
    "# gp = voice_opp_len_11.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_11_opp_num_11_cnt0'] = x['0']\n",
    "# voice_feature['voice_opp_len_11_opp_num_11_cnt1'] = x['1']\n",
    "# gp = voice_opp_len_11.groupby(['uid','in_out'])['opp_len']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_11_len_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_11_len_mean_in'] = x['1']\n",
    "# gp = voice_opp_len_11.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_11_head_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_11_head_mean_in'] = x['1']\n",
    "# gp = voice_opp_len_11.groupby(['uid','in_out'])['start_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_11_start_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_11_start_mean_in'] = x['1']\n",
    "# #打入的平均时长，打出的平均时长\n",
    "# gp = voice_opp_len_11.groupby(['uid','in_out'])['voice_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_11_time_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_11_time_mean_in'] = x['1']\n",
    "# gp = voice_opp_len_11.groupby(['uid','in_out'])['date']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_11_date_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_11_date_mean_in'] = x['1']\n",
    "# # gp = voice_opp_len_11.groupby(['uid','call_type'])['date']\n",
    "# # x = gp.apply(lambda x:x.mean())\n",
    "# # x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# # x.columns = ['1','2','3','4']\n",
    "# # voice_feature['voice_opp_len_11_date_mean_type1'] = x['1']\n",
    "# # voice_feature['voice_opp_len_11_date_mean_type2'] = x['2']\n",
    "# # voice_feature['voice_opp_len_11_date_mean_type3'] = x['3']\n",
    "# # #不同类型的通话数量\n",
    "# # gp = voice_opp_len_11.groupby(['uid','call_type'])['opp_num']\n",
    "# # x = gp.apply(lambda x:x.count())\n",
    "# # x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# # x.columns = ['1','2','3','4']\n",
    "# # voice_feature['voice_opp_len_11_num_cnt_type1'] = x['1']\n",
    "# # voice_feature['voice_opp_len_11_num_cnt_type2'] = x['2']\n",
    "# # voice_feature['voice_opp_len_11_num_cnt_type3'] = x['3']\n",
    "# # #不同类型号码长度均值\n",
    "# # gp = voice_opp_len_11.groupby(['uid','call_type'])['opp_len']\n",
    "# # x = gp.apply(lambda x:x.mean())\n",
    "# # x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# # x.columns = ['1','2','3','4']\n",
    "# # voice_feature['voice_opp_len_11_len_mean_type1'] = x['1']\n",
    "# # voice_feature['voice_opp_len_11_len_mean_type2'] = x['2']\n",
    "# # voice_feature['voice_opp_len_11_len_mean_type3'] = x['3']\n",
    "# # #不同类型的头部均值\n",
    "# # gp = voice_opp_len_11.groupby(['uid','call_type'])['opp_head']\n",
    "# # x = gp.apply(lambda x:x.mean())\n",
    "# # x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# # x.columns = ['1','2','3','4']\n",
    "# # voice_feature['voice_opp_len_11_head_mean_type1'] = x['1']\n",
    "# # voice_feature['voice_opp_len_11_head_mean_type2'] = x['2']\n",
    "# # voice_feature['voice_opp_len_11_head_mean_type3'] = x['3']\n",
    "# # #不同类型的开始时间均值\n",
    "# # gp = voice_opp_len_11.groupby(['uid','call_type'])['voice_time']\n",
    "# # x = gp.apply(lambda x:x.mean())\n",
    "# # x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# # x.columns = ['1','2','3','4']\n",
    "# # voice_feature['voice_opp_len_11_time_mean_type1'] = x['1']\n",
    "# # voice_feature['voice_opp_len_11_time_mean_type2'] = x['2']\n",
    "# # voice_feature['voice_opp_len_11_time_mean_type3'] = x['3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voice_opp_len_13 = pd.DataFrame()\n",
    "# voice_opp_len_13 = voice[voice['opp_len']==13]\n",
    "# gp = voice_opp_len_13.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_13_opp_num_13_cnt0'] = x['0']\n",
    "# voice_feature['voice_opp_len_13_opp_num_13_cnt1'] = x['1']\n",
    "# gp = voice_opp_len_13.groupby(['uid','in_out'])['opp_len']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_13_len_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_13_len_mean_in'] = x['1']\n",
    "# gp = voice_opp_len_13.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_13_head_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_13_head_mean_in'] = x['1']\n",
    "# gp = voice_opp_len_13.groupby(['uid','in_out'])['start_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_13_start_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_13_start_mean_in'] = x['1']\n",
    "# #打入的平均时长，打出的平均时长\n",
    "# gp = voice_opp_len_13.groupby(['uid','in_out'])['voice_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_13_time_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_13_time_mean_in'] = x['1']\n",
    "# gp = voice_opp_len_13.groupby(['uid','in_out'])['date']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_13_date_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_13_date_mean_in'] = x['1']\n",
    "# \n",
    "# \n",
    "# # gp = voice_opp_len_13.groupby(['uid','call_type'])['date']\n",
    "# # x = gp.apply(lambda x:x.mean())\n",
    "# # x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# # x.columns = ['1','2','3','4']\n",
    "# # voice_feature['voice_opp_len_13_date_mean_type1'] = x['1']\n",
    "# # voice_feature['voice_opp_len_13_date_mean_type2'] = x['2']\n",
    "# # voice_feature['voice_opp_len_13_date_mean_type3'] = x['3']\n",
    "# # #不同类型的通话数量\n",
    "# # gp = voice_opp_len_13.groupby(['uid','call_type'])['opp_num']\n",
    "# # x = gp.apply(lambda x:x.count())\n",
    "# # x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# # x.columns = ['1','2','3','4']\n",
    "# # voice_feature['voice_opp_len_13_num_cnt_type1'] = x['1']\n",
    "# # voice_feature['voice_opp_len_13_num_cnt_type2'] = x['2']\n",
    "# # voice_feature['voice_opp_len_13_num_cnt_type3'] = x['3']\n",
    "# # #不同类型号码长度均值\n",
    "# # gp = voice_opp_len_13.groupby(['uid','call_type'])['opp_len']\n",
    "# # x = gp.apply(lambda x:x.mean())\n",
    "# # x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# # x.columns = ['1','2','3','4']\n",
    "# # voice_feature['voice_opp_len_13_len_mean_type1'] = x['1']\n",
    "# # voice_feature['voice_opp_len_13_len_mean_type2'] = x['2']\n",
    "# # voice_feature['voice_opp_len_13_len_mean_type3'] = x['3']\n",
    "# # #不同类型的头部均值\n",
    "# # gp = voice_opp_len_13.groupby(['uid','call_type'])['opp_head']\n",
    "# # x = gp.apply(lambda x:x.mean())\n",
    "# # x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# # x.columns = ['1','2','3','4']\n",
    "# # voice_feature['voice_opp_len_13_head_mean_type1'] = x['1']\n",
    "# # voice_feature['voice_opp_len_13_head_mean_type2'] = x['2']\n",
    "# # voice_feature['voice_opp_len_13_head_mean_type3'] = x['3']\n",
    "# # #不同类型的开始时间均值\n",
    "# # gp = voice_opp_len_13.groupby(['uid','call_type'])['voice_time']\n",
    "# # x = gp.apply(lambda x:x.mean())\n",
    "# # x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# # x.columns = ['1','2','3','4']\n",
    "# # voice_feature['voice_opp_len_13_time_mean_type1'] = x['1']\n",
    "# # voice_feature['voice_opp_len_13_time_mean_type2'] = x['2']\n",
    "# # voice_feature['voice_opp_len_13_time_mean_type3'] = x['3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voice_opp_len_12 = pd.DataFrame()\n",
    "# voice_opp_len_12 = voice[voice['opp_len']==12]\n",
    "# gp = voice_opp_len_12.groupby(['uid','in_out'])['opp_num']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_12_opp_num_12_cnt0'] = x['0']\n",
    "# voice_feature['voice_opp_len_12_opp_num_12_cnt1'] = x['1']\n",
    "# gp = voice_opp_len_12.groupby(['uid','in_out'])['opp_len']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_12_len_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_12_len_mean_in'] = x['1']\n",
    "# gp = voice_opp_len_12.groupby(['uid','in_out'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_12_head_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_12_head_mean_in'] = x['1']\n",
    "# gp = voice_opp_len_12.groupby(['uid','in_out'])['start_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_12_start_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_12_start_mean_in'] = x['1']\n",
    "# #打入的平均时长，打出的平均时长\n",
    "# gp = voice_opp_len_12.groupby(['uid','in_out'])['voice_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_12_time_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_12_time_mean_in'] = x['1']\n",
    "# gp = voice_opp_len_12.groupby(['uid','in_out'])['date']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# voice_feature['voice_opp_len_12_date_mean_out'] = x['0']\n",
    "# voice_feature['voice_opp_len_12_date_mean_in'] = x['1']\n",
    "\n",
    "\n",
    "# gp = voice_opp_len_12.groupby(['uid','call_type'])['date']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['1','2','3']\n",
    "# voice_feature['voice_opp_len_12_date_mean_type1'] = x['1']\n",
    "# voice_feature['voice_opp_len_12_date_mean_type2'] = x['2']\n",
    "# voice_feature['voice_opp_len_12_date_mean_type3'] = x['3']\n",
    "# #不同类型的通话数量\n",
    "# gp = voice_opp_len_12.groupby(['uid','call_type'])['opp_num']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['1','2','3','4']\n",
    "# voice_feature['voice_opp_len_12_num_cnt_type1'] = x['1']\n",
    "# voice_feature['voice_opp_len_12_num_cnt_type2'] = x['2']\n",
    "# voice_feature['voice_opp_len_12_num_cnt_type3'] = x['3']\n",
    "# #不同类型号码长度均值\n",
    "# gp = voice_opp_len_12.groupby(['uid','call_type'])['opp_len']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['1','2','3','4']\n",
    "# voice_feature['voice_opp_len_12_len_mean_type1'] = x['1']\n",
    "# voice_feature['voice_opp_len_12_len_mean_type2'] = x['2']\n",
    "# voice_feature['voice_opp_len_12_len_mean_type3'] = x['3']\n",
    "# #不同类型的头部均值\n",
    "# gp = voice_opp_len_12.groupby(['uid','call_type'])['opp_head']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['1','2','3','4']\n",
    "# voice_feature['voice_opp_len_12_head_mean_type1'] = x['1']\n",
    "# voice_feature['voice_opp_len_12_head_mean_type2'] = x['2']\n",
    "# voice_feature['voice_opp_len_12_head_mean_type3'] = x['3']\n",
    "# #不同类型的开始时间均值\n",
    "# gp = voice_opp_len_12.groupby(['uid','call_type'])['voice_time']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['1','2','3','4']\n",
    "# voice_feature['voice_opp_len_12_time_mean_type1'] = x['1']\n",
    "# voice_feature['voice_opp_len_12_time_mean_type2'] = x['2']\n",
    "# voice_feature['voice_opp_len_12_time_mean_type3'] = x['3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = train_feature.merge(voice_feature,on='uid',how='left').reset_index(drop=True)\n",
    "train_feature = train_feature.fillna(0)\n",
    "test_feature = test_feature.merge(voice_feature,on='uid',how='left').reset_index(drop=True)\n",
    "test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_feature = pd.DataFrame()\n",
    "#上网总天数\n",
    "gp = wa.groupby('uid')['date']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "wa_feature['uid'] = x.index\n",
    "wa_feature['wa_visit_date_cnt'] = x.values\n",
    "#访问次数\n",
    "gp = wa.groupby('uid')['visit_cnt']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "wa_feature['wa_visit_cnt_sum'] = x.values\n",
    "# \n",
    "gp = wa.groupby('uid')['visit_cnt']\n",
    "x = gp.apply(lambda x:x.max())\n",
    "wa_feature['wa_visit_cnt_max'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['visit_cnt']\n",
    "x = gp.apply(lambda x:x.std())\n",
    "wa_feature['wa_visit_cnt_std'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['visit_cnt']\n",
    "x = gp.apply(lambda x:x.median())\n",
    "wa_feature['wa_visit_cnt_median'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['visit_cnt']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "wa_feature['wa_visit_cnt_mean'] = x.values\n",
    "#访问时长\n",
    "\n",
    "gp = wa.groupby('uid')['visit_dura']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "wa_feature['wa_visit_dura_sum'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['visit_dura']\n",
    "x = gp.apply(lambda x:x.max())\n",
    "wa_feature['wa_visit_dura_max'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['visit_dura']\n",
    "x = gp.apply(lambda x:x.std())\n",
    "wa_feature['wa_visit_dura_std'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['visit_dura']\n",
    "x = gp.apply(lambda x:x.median())\n",
    "wa_feature['wa_visit_dura_median'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['visit_dura']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "wa_feature['wa_visit_dura_mean'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['down_flow']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "wa_feature['wa_down_flow_mean'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['down_flow']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "wa_feature['wa_down_flow_sum'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['down_flow']\n",
    "x = gp.apply(lambda x:x.max())\n",
    "wa_feature['wa_down_flow_max'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['down_flow']\n",
    "x = gp.apply(lambda x:x.median())\n",
    "wa_feature['wa_down_flow_median'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['down_flow']\n",
    "x = gp.apply(lambda x:x.std())\n",
    "wa_feature['wa_down_flow_std'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['up_flow']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "wa_feature['wa_up_flow_mean'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['up_flow']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "wa_feature['wa_up_flow_sum'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['up_flow']\n",
    "x = gp.apply(lambda x:x.max())\n",
    "wa_feature['wa_up_flow_max'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['up_flow']\n",
    "x = gp.apply(lambda x:x.std())\n",
    "wa_feature['wa_up_flow_std'] = x.values\n",
    "\n",
    "gp = wa.groupby('uid')['up_flow']\n",
    "x = gp.apply(lambda x:x.median())\n",
    "wa_feature['wa_up_flow_median'] = x.values\n",
    "\n",
    "#总流量\n",
    "wa['flow'] = wa['down_flow'] + wa['up_flow']\n",
    "gp = wa.groupby('uid')['flow']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "wa_feature['wa_flow'] =  x.values \n",
    "\n",
    "#APP/网站访问天数\n",
    "gp = wa.groupby(['uid','wa_type'])['date']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "wa_feature['wa_type0_date_mean'] = x['0']\n",
    "wa_feature['wa_type1_date_mean'] = x['1']\n",
    "\n",
    "gp = wa.groupby(['uid','wa_type'])['date']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "wa_feature['wa_type0_date_cnt'] = x['0']\n",
    "wa_feature['wa_type1_date_cnt'] = x['1']\n",
    "\n",
    "#APP/网站访问总次数\n",
    "gp = wa.groupby(['uid','wa_type'])['visit_cnt']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "wa_feature['wa_type0_visitcnt_all'] = x['0']\n",
    "wa_feature['wa_type1_visitcnt_all'] = x['1']\n",
    "\n",
    "gp = wa.groupby(['uid','wa_type'])['visit_cnt']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "wa_feature['wa_type0_visitcnt_mean'] = x['0']\n",
    "wa_feature['wa_type1_visitcnt_mean'] = x['1']\n",
    "\n",
    "#APP/网站上载量\n",
    "gp = wa.groupby(['uid','wa_type'])['up_flow']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "wa_feature['wa_type0_upflow_all'] = x['0']\n",
    "wa_feature['wa_type1_upflow_all'] = x['1']\n",
    "\n",
    "gp = wa.groupby(['uid','wa_type'])['up_flow']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "wa_feature['wa_type0_upflow_mean'] = x['0']\n",
    "wa_feature['wa_type1_upflow_mean'] = x['1']\n",
    "\n",
    "#APP/网站下载量\n",
    "gp = wa.groupby(['uid','wa_type'])['down_flow']\n",
    "x = gp.apply(lambda x:x.sum())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "wa_feature['wa_type0_downflow_all'] = x['0']\n",
    "wa_feature['wa_type1_downflow_all'] = x['1']\n",
    "gp = wa.groupby(['uid','wa_type'])['down_flow']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "wa_feature['wa_type0_downflow_mean'] = x['0']\n",
    "wa_feature['wa_type1_downflow_mean'] = x['1']\n",
    "\n",
    "gp = wa.groupby(['uid','wa_type'])['flow']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "wa_feature['wa_type0_flow_mean'] = x['0']\n",
    "wa_feature['wa_type1_flow_mean'] = x['1']\n",
    "\n",
    "#APP/网站访问平均时长\n",
    "gp = wa.groupby(['uid','wa_type'])['visit_dura']\n",
    "x = gp.apply(lambda x:x.mean())\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "wa_feature['wa_type0_dura_mean'] = x['0']\n",
    "wa_feature['wa_type1_dura_mean'] = x['1']\n",
    "\n",
    "gp=wa.groupby('uid')['wa_name']\n",
    "x=gp.apply(lambda x:len(set(x)))\n",
    "wa_feature['wa_name_count_uinque']=x.values\n",
    "\n",
    "#APP/网站分别访问了多少种\n",
    "gp = wa.groupby(['uid','wa_type'])['wa_name']\n",
    "x = gp.apply(lambda x:len(set(x)))\n",
    "x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "x.columns = ['0','1']\n",
    "wa_feature['wa_type0_name_unique'] = x['0']\n",
    "wa_feature['wa_type1_name_unique'] = x['1']\n",
    "\n",
    "\n",
    "wa_feature['wa_namecnt_perday'] = wa_feature['wa_name_count_uinque'] / wa_feature['wa_visit_date_cnt']\n",
    "wa_feature['wa_dura_sum_percnt'] =  wa_feature['wa_visit_dura_sum'] / wa_feature['wa_visit_cnt_sum']\n",
    "wa_feature['wa_type0_namecnt_perday'] = wa_feature['wa_type0_name_unique'] / wa_feature['wa_type0_date_cnt']\n",
    "wa_feature['wa_type1_namecnt_perday'] = wa_feature['wa_type1_name_unique'] / wa_feature['wa_type1_date_cnt']\n",
    "wa_feature['wa_type0_namedura_perday'] = wa_feature['wa_type0_name_unique'] / wa_feature['wa_type0_dura_mean']\n",
    "wa_feature['wa_type1_namedura_perday'] = wa_feature['wa_type1_name_unique'] / wa_feature['wa_type1_dura_mean']\n",
    "wa_feature['wa_type0_namevicnt_perday'] = wa_feature['wa_type0_name_unique'] / wa_feature['wa_type0_visitcnt_mean']\n",
    "wa_feature['wa_type1_namevicnt_perday'] = wa_feature['wa_type1_name_unique'] / wa_feature['wa_type1_visitcnt_mean']\n",
    "wa_feature['wa_type0_namevicntall_perday'] = wa_feature['wa_type0_name_unique'] / wa_feature['wa_type0_visitcnt_all']\n",
    "wa_feature['wa_type1_namevicntall_perday'] = wa_feature['wa_type1_name_unique'] / wa_feature['wa_type1_visitcnt_all']\n",
    "wa_feature['wa_type0_dura_perday'] = wa_feature['wa_type0_dura_mean'] / wa_feature['wa_type0_date_cnt']\n",
    "wa_feature['wa_type1_dura_perday'] = wa_feature['wa_type1_dura_mean'] / wa_feature['wa_type1_date_cnt']\n",
    "wa_feature['wa_type0_up_persec'] = wa_feature['wa_type0_upflow_all'] / wa_feature['wa_type0_dura_mean']\n",
    "wa_feature['wa_type1_up_persec'] = wa_feature['wa_type1_upflow_all'] / wa_feature['wa_type1_dura_mean']\n",
    "wa_feature['wa_type0_down_percnt'] = wa_feature['wa_type0_downflow_all'] / wa_feature['wa_type0_visitcnt_mean']\n",
    "wa_feature['wa_type1_down_percnt'] = wa_feature['wa_type1_downflow_all'] / wa_feature['wa_type1_visitcnt_mean']\n",
    "\n",
    "# #######################################\n",
    "wa_feature['wa_visitdura_perday'] = wa_feature['wa_visit_dura_sum'] / wa_feature['wa_visit_date_cnt']\n",
    "wa_feature['wa_visitcnt_perday'] = wa_feature['wa_visit_cnt_sum'] / wa_feature['wa_visit_date_cnt']\n",
    "wa_feature['wa_namedura_perday'] = wa_feature['wa_name_count_uinque'] / wa_feature['wa_visit_dura_sum']\n",
    "wa_feature['wa_namevicnt_perday'] = wa_feature['wa_name_count_uinque'] / wa_feature['wa_visit_cnt_sum']\n",
    "wa_feature['wa_type0_visitcnt_perday'] = wa_feature['wa_type0_visitcnt_all'] / wa_feature['wa_type0_date_cnt']\n",
    "wa_feature['wa_type1_visitcnt_perday'] = wa_feature['wa_type1_visitcnt_all'] / wa_feature['wa_type1_date_cnt']\n",
    "wa_feature['wa_flow_sum_percnt'] =  wa_feature['wa_flow'] /wa_feature['wa_visit_cnt_sum']\n",
    "wa_feature['wa_flow_sum_persecond'] =  wa_feature['wa_flow'] / wa_feature['wa_visit_dura_sum']\n",
    "wa_feature['wa_flow_sum_perday'] = wa_feature['wa_flow'] / wa_feature['wa_visit_date_cnt']\n",
    "wa_feature['wa_upflow_perday'] = wa_feature['wa_up_flow_sum'] / wa_feature['wa_visit_date_cnt']\n",
    "wa_feature['wa_downflow_perday'] = wa_feature['wa_down_flow_sum'] / wa_feature['wa_visit_date_cnt']\n",
    "wa_feature['wa_upflowcnt_perday'] = wa_feature['wa_up_flow_sum'] / wa_feature['wa_visit_cnt_mean']\n",
    "wa_feature['wa_downflowcnt_perday'] = wa_feature['wa_down_flow_sum'] / wa_feature['wa_visit_cnt_mean']\n",
    "wa_feature['wa_upflowdura_persec'] = wa_feature['wa_up_flow_sum'] / wa_feature['wa_visit_dura_mean']\n",
    "wa_feature['wa_downflowdura_persec'] = wa_feature['wa_down_flow_sum'] / wa_feature['wa_visit_dura_mean']\n",
    "wa_feature['wa_type0_up_perday'] = wa_feature['wa_type0_upflow_all'] / wa_feature['wa_type0_date_cnt']\n",
    "wa_feature['wa_type1_up_perday'] = wa_feature['wa_type1_upflow_all'] / wa_feature['wa_type1_date_cnt']\n",
    "wa_feature['wa_type0_down_perday'] = wa_feature['wa_type0_downflow_all'] / wa_feature['wa_type0_date_cnt']\n",
    "wa_feature['wa_type1_down_perday'] = wa_feature['wa_type1_downflow_all'] / wa_feature['wa_type1_date_cnt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = train_feature.merge(wa_feature,on='uid',how='left').reset_index(drop=True)\n",
    "train_feature = train_feature.fillna(0)\n",
    "test_feature = test_feature.merge(wa_feature,on='uid',how='left').reset_index(drop=True)\n",
    "test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date1 = pd.DataFrame()\n",
    "# date1 = wa[wa['date']<=9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date1_feature = pd.DataFrame()\n",
    "# #上网总天数\n",
    "# gp = date1.groupby('uid')['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# date1_feature['uid'] = x.index\n",
    "# date1_feature['date1_visit_date_cnt'] = x.values\n",
    "# \n",
    "# gp = date1.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date1_feature['date1_visit_cnt_mean'] = x.values\n",
    "# #访问时长\n",
    "# # \n",
    "# gp = date1.groupby('uid')['visit_dura']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date1_feature['date1_visit_dura_sum'] = x.values\n",
    "# \n",
    "# gp = date1.groupby('uid')['visit_dura']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date1_feature['date1_visit_dura_mean'] = x.values\n",
    "# \n",
    "# gp = date1.groupby('uid')['down_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date1_feature['date1_down_flow_mean'] = x.values\n",
    "# \n",
    "# gp = date1.groupby('uid')['up_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date1_feature['date1_up_flow_mean'] = x.values\n",
    "# \n",
    "# #总流量\n",
    "# date1['flow'] = date1['down_flow'] + date1['up_flow']\n",
    "# gp = date1.groupby('uid')['flow']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date1_feature['date1_flow_sum'] = x.values\n",
    "# \n",
    "# gp = date1.groupby('uid')['date']\n",
    "# y = gp.apply(lambda x:len(set(x)))\n",
    "# date1_feature['date1_flow_perday_mean'] = date1_feature['date1_flow_sum'] / y.values\n",
    "# \n",
    "# gp = date1.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date1_feature['date1_flow_sum_percnt'] = date1_feature['date1_flow_sum'] / x.values \n",
    "# \n",
    "# gp = date1.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date1_feature['date1_dura_sum_percnt'] = date1_feature['date1_visit_dura_sum'] / x.values \n",
    "# \n",
    "# #APP/网站访问天数\n",
    "# gp = date1.groupby(['uid','wa_type'])['date']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# date1_feature['date1_type0_date_mean'] = x['0']\n",
    "# date1_feature['date1_type1_date_mean'] = x['1']\n",
    "# \n",
    "# gp = date1.groupby(['uid','wa_type'])['date']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# date1_feature['date1_type0_date_cnt'] = x['0']\n",
    "# date1_feature['date1_type1_date_cnt'] = x['1']\n",
    "# \n",
    "# #APP/网站访问总次数\n",
    "# \n",
    "# gp = date1.groupby(['uid','wa_type'])['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# date1_feature['date1_type0_visitcnt_mean'] = x['0']\n",
    "# date1_feature['date1_type1_visitcnt_mean'] = x['1']\n",
    "# \n",
    "# #APP/网站上载量\n",
    "# gp = date1.groupby(['uid','wa_type'])['up_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# date1_feature['date1_type0_upflow_mean'] = x['0']\n",
    "# date1_feature['date1_type1_upflow_mean'] = x['1']\n",
    "# #APP/网站下载量\n",
    "# gp = date1.groupby(['uid','wa_type'])['down_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# date1_feature['date1_type0_downflow_mean'] = x['0']\n",
    "# date1_feature['date1_type1_downflow_mean'] = x['1']\n",
    "# gp = date1.groupby(['uid','wa_type'])['flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# date1_feature['date1_type0_flow_mean'] = x['0']\n",
    "# date1_feature['date1_type1_flow_mean'] = x['1']\n",
    "# #APP/网站访问平均时长\n",
    "# gp = date1.groupby(['uid','wa_type'])['visit_dura']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# date1_feature['date1_type0_dura_mean'] = x['0']\n",
    "# date1_feature['date1_type1_dura_mean'] = x['1']\n",
    "# \n",
    "# gp=date1.groupby('uid')['wa_name']\n",
    "# x=gp.apply(lambda x:len(set(x)))\n",
    "# date1_feature['date1_name_count_uinque']=x.values\n",
    "# #APP/网站分别访问了多少种\n",
    "# gp = date1.groupby(['uid','wa_type'])['wa_name']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','1']\n",
    "# date1_feature['date1_type0_name_unique'] = x['0']\n",
    "# date1_feature['date1_type1_name_unique'] = x['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature = train_feature.merge(date1_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# train_feature = train_feature.fillna(0)\n",
    "# test_feature = test_feature.merge(date1_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date2 = pd.DataFrame()\n",
    "# date2 = wa[wa['date']>9]\n",
    "# date2 = date2[date2['date']<=18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date2_feature = pd.DataFrame()\n",
    "# #上网总天数\n",
    "# gp = date2.groupby('uid')['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# date2_feature['uid'] = x.index\n",
    "# date2_feature['date2_visit_date_cnt'] = x.values\n",
    "# \n",
    "# gp = date2.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date2_feature['date2_visit_cnt_mean'] = x.values\n",
    "# #访问时长\n",
    "# # \n",
    "# gp = date2.groupby('uid')['visit_dura']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date2_feature['date2_visit_dura_sum'] = x.values\n",
    "# \n",
    "# gp = date2.groupby('uid')['visit_dura']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date2_feature['date2_visit_dura_mean'] = x.values\n",
    "# \n",
    "# gp = date2.groupby('uid')['down_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date2_feature['date2_down_flow_mean'] = x.values\n",
    "# \n",
    "# gp = date2.groupby('uid')['up_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date2_feature['date2_up_flow_mean'] = x.values\n",
    "# \n",
    "# #总流量\n",
    "# date2['flow'] = date2['down_flow'] + date2['up_flow']\n",
    "# gp = date2.groupby('uid')['flow']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date2_feature['date2_flow_sum'] = x.values\n",
    "# \n",
    "# gp = date2.groupby('uid')['date']\n",
    "# y = gp.apply(lambda x:len(set(x)))\n",
    "# date2_feature['date2_flow_perday_mean'] = date2_feature['date2_flow_sum'] / y.values\n",
    "# \n",
    "# gp = date2.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date2_feature['date2_flow_sum_percnt'] = date2_feature['date2_flow_sum'] / x.values \n",
    "# \n",
    "# gp = date2.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date2_feature['date2_dura_sum_percnt'] = date2_feature['date2_visit_dura_sum'] / x.values \n",
    "# \n",
    "# #APP/网站访问天数\n",
    "# gp = date2.groupby(['uid','wa_type'])['date']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# date2_feature['date2_type0_date_mean'] = x['0']\n",
    "# date2_feature['date2_type2_date_mean'] = x['2']\n",
    "# \n",
    "# gp = date2.groupby(['uid','wa_type'])['date']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# date2_feature['date2_type0_date_cnt'] = x['0']\n",
    "# date2_feature['date2_type2_date_cnt'] = x['2']\n",
    "# \n",
    "# #APP/网站访问总次数\n",
    "# \n",
    "# gp = date2.groupby(['uid','wa_type'])['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# date2_feature['date2_type0_visitcnt_mean'] = x['0']\n",
    "# date2_feature['date2_type2_visitcnt_mean'] = x['2']\n",
    "# \n",
    "# #APP/网站上载量\n",
    "# gp = date2.groupby(['uid','wa_type'])['up_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# date2_feature['date2_type0_upflow_mean'] = x['0']\n",
    "# date2_feature['date2_type2_upflow_mean'] = x['2']\n",
    "# #APP/网站下载量\n",
    "# gp = date2.groupby(['uid','wa_type'])['down_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# date2_feature['date2_type0_downflow_mean'] = x['0']\n",
    "# date2_feature['date2_type2_downflow_mean'] = x['2']\n",
    "# gp = date2.groupby(['uid','wa_type'])['flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# date2_feature['date2_type0_flow_mean'] = x['0']\n",
    "# date2_feature['date2_type2_flow_mean'] = x['2']\n",
    "# #APP/网站访问平均时长\n",
    "# gp = date2.groupby(['uid','wa_type'])['visit_dura']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# date2_feature['date2_type0_dura_mean'] = x['0']\n",
    "# date2_feature['date2_type2_dura_mean'] = x['2']\n",
    "# \n",
    "# gp=date2.groupby('uid')['wa_name']\n",
    "# x=gp.apply(lambda x:len(set(x)))\n",
    "# date2_feature['date2_name_count_uinque']=x.values\n",
    "# #APP/网站分别访问了多少种\n",
    "# gp = date2.groupby(['uid','wa_type'])['wa_name']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','2']\n",
    "# date2_feature['date2_type0_name_unique'] = x['0']\n",
    "# date2_feature['date2_type2_name_unique'] = x['2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature = train_feature.merge(date2_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# train_feature = train_feature.fillna(0)\n",
    "# test_feature = test_feature.merge(date2_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date3 = pd.DataFrame()\n",
    "# date3 = wa[wa['date']>18]\n",
    "# date3 = date3[date3['date']<=27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date3_feature = pd.DataFrame()\n",
    "# #上网总天数\n",
    "# gp = date3.groupby('uid')['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# date3_feature['uid'] = x.index\n",
    "# date3_feature['date3_visit_date_cnt'] = x.values\n",
    "# \n",
    "# gp = date3.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date3_feature['date3_visit_cnt_mean'] = x.values\n",
    "# #访问时长\n",
    "# # \n",
    "# gp = date3.groupby('uid')['visit_dura']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date3_feature['date3_visit_dura_sum'] = x.values\n",
    "# \n",
    "# gp = date3.groupby('uid')['visit_dura']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date3_feature['date3_visit_dura_mean'] = x.values\n",
    "# \n",
    "# gp = date3.groupby('uid')['down_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date3_feature['date3_down_flow_mean'] = x.values\n",
    "# \n",
    "# gp = date3.groupby('uid')['up_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date3_feature['date3_up_flow_mean'] = x.values\n",
    "# \n",
    "# #总流量\n",
    "# date3['flow'] = date3['down_flow'] + date3['up_flow']\n",
    "# gp = date3.groupby('uid')['flow']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date3_feature['date3_flow_sum'] = x.values\n",
    "# \n",
    "# gp = date3.groupby('uid')['date']\n",
    "# y = gp.apply(lambda x:len(set(x)))\n",
    "# date3_feature['date3_flow_perday_mean'] = date3_feature['date3_flow_sum'] / y.values\n",
    "# \n",
    "# gp = date3.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date3_feature['date3_flow_sum_percnt'] = date3_feature['date3_flow_sum'] / x.values \n",
    "# \n",
    "# gp = date3.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date3_feature['date3_dura_sum_percnt'] = date3_feature['date3_visit_dura_sum'] / x.values \n",
    "# \n",
    "# #APP/网站访问天数\n",
    "# gp = date3.groupby(['uid','wa_type'])['date']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# date3_feature['date3_type0_date_mean'] = x['0']\n",
    "# date3_feature['date3_type3_date_mean'] = x['3']\n",
    "# \n",
    "# gp = date3.groupby(['uid','wa_type'])['date']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# date3_feature['date3_type0_date_cnt'] = x['0']\n",
    "# date3_feature['date3_type3_date_cnt'] = x['3']\n",
    "# \n",
    "# #APP/网站访问总次数\n",
    "# \n",
    "# gp = date3.groupby(['uid','wa_type'])['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# date3_feature['date3_type0_visitcnt_mean'] = x['0']\n",
    "# date3_feature['date3_type3_visitcnt_mean'] = x['3']\n",
    "# \n",
    "# #APP/网站上载量\n",
    "# gp = date3.groupby(['uid','wa_type'])['up_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# date3_feature['date3_type0_upflow_mean'] = x['0']\n",
    "# date3_feature['date3_type3_upflow_mean'] = x['3']\n",
    "# #APP/网站下载量\n",
    "# gp = date3.groupby(['uid','wa_type'])['down_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# date3_feature['date3_type0_downflow_mean'] = x['0']\n",
    "# date3_feature['date3_type3_downflow_mean'] = x['3']\n",
    "# gp = date3.groupby(['uid','wa_type'])['flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# date3_feature['date3_type0_flow_mean'] = x['0']\n",
    "# date3_feature['date3_type3_flow_mean'] = x['3']\n",
    "# #APP/网站访问平均时长\n",
    "# gp = date3.groupby(['uid','wa_type'])['visit_dura']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# date3_feature['date3_type0_dura_mean'] = x['0']\n",
    "# date3_feature['date3_type3_dura_mean'] = x['3']\n",
    "# \n",
    "# gp=date3.groupby('uid')['wa_name']\n",
    "# x=gp.apply(lambda x:len(set(x)))\n",
    "# date3_feature['date3_name_count_uinque']=x.values\n",
    "# #APP/网站分别访问了多少种\n",
    "# gp = date3.groupby(['uid','wa_type'])['wa_name']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','3']\n",
    "# date3_feature['date3_type0_name_unique'] = x['0']\n",
    "# date3_feature['date3_type3_name_unique'] = x['3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature = train_feature.merge(date3_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# train_feature = train_feature.fillna(0)\n",
    "# test_feature = test_feature.merge(date3_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date4 = pd.DataFrame()\n",
    "# date4 = wa[wa['date']>27]\n",
    "# date4 = date4[date4['date']<=36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date4_feature = pd.DataFrame()\n",
    "# #上网总天数\n",
    "# gp = date4.groupby('uid')['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# date4_feature['uid'] = x.index\n",
    "# date4_feature['date4_visit_date_cnt'] = x.values\n",
    "# #访问次数\n",
    "# # gp = date4.groupby('uid')['visit_cnt']\n",
    "# # x = gp.apply(lambda x:x.sum())\n",
    "# # date4_feature['date4_visit_cnt_sum'] = x.values\n",
    "# # \n",
    "# # gp = date4.groupby('uid')['visit_cnt']\n",
    "# # x = gp.apply(lambda x:x.max())\n",
    "# # date4_feature['date4_visit_cnt_max'] = x.values\n",
    "# # \n",
    "# # gp = date4.groupby('uid')['visit_cnt']\n",
    "# # x = gp.apply(lambda x:x.std())\n",
    "# # date4_feature['date4_visit_cnt_std'] = x.values\n",
    "# # \n",
    "# # gp = date4.groupby('uid')['visit_cnt']\n",
    "# # x = gp.apply(lambda x:x.median())\n",
    "# # date4_feature['date4_visit_cnt_median'] = x.values\n",
    "# # \n",
    "# gp = date4.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date4_feature['date4_visit_cnt_mean'] = x.values\n",
    "# #访问时长\n",
    "# # \n",
    "# gp = date4.groupby('uid')['visit_dura']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date4_feature['date4_visit_dura_sum'] = x.values\n",
    "# \n",
    "# # gp = date4.groupby('uid')['visit_dura']\n",
    "# # x = gp.apply(lambda x:x.max())\n",
    "# # date4_feature['date4_visit_dura_max'] = x.values\n",
    "# # \n",
    "# # gp = date4.groupby('uid')['visit_dura']\n",
    "# # x = gp.apply(lambda x:x.std())\n",
    "# # date4_feature['date4_visit_dura_std'] = x.values\n",
    "# # \n",
    "# # gp = date4.groupby('uid')['visit_dura']\n",
    "# # x = gp.apply(lambda x:x.median())\n",
    "# # date4_feature['date4_visit_dura_median'] = x.values\n",
    "# \n",
    "# gp = date4.groupby('uid')['visit_dura']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date4_feature['date4_visit_dura_mean'] = x.values\n",
    "# \n",
    "# gp = date4.groupby('uid')['down_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date4_feature['date4_down_flow_mean'] = x.values\n",
    "# \n",
    "# # gp = date4.groupby('uid')['down_flow']\n",
    "# # x = gp.apply(lambda x:x.sum())\n",
    "# # date4_feature['date4_down_flow_sum'] = x.values\n",
    "# # \n",
    "# # gp = date4.groupby('uid')['down_flow']\n",
    "# # x = gp.apply(lambda x:x.max())\n",
    "# # date4_feature['date4_down_flow_max'] = x.values\n",
    "# # \n",
    "# # gp = date4.groupby('uid')['down_flow']\n",
    "# # x = gp.apply(lambda x:x.median())\n",
    "# # date4_feature['date4_down_flow_median'] = x.values\n",
    "# # \n",
    "# # gp = date4.groupby('uid')['down_flow']\n",
    "# # x = gp.apply(lambda x:x.std())\n",
    "# # date4_feature['date4_down_flow_std'] = x.values\n",
    "# \n",
    "# gp = date4.groupby('uid')['up_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date4_feature['date4_up_flow_mean'] = x.values\n",
    "# \n",
    "# # gp = date4.groupby('uid')['up_flow']\n",
    "# # x = gp.apply(lambda x:x.sum())\n",
    "# # date4_feature['date4_up_flow_sum'] = x.values\n",
    "# # \n",
    "# # gp = date4.groupby('uid')['up_flow']\n",
    "# # x = gp.apply(lambda x:x.max())\n",
    "# # date4_feature['date4_up_flow_max'] = x.values\n",
    "# # \n",
    "# # gp = date4.groupby('uid')['up_flow']\n",
    "# # x = gp.apply(lambda x:x.std())\n",
    "# # date4_feature['date4_up_flow_std'] = x.values\n",
    "# # \n",
    "# # gp = date4.groupby('uid')['up_flow']\n",
    "# # x = gp.apply(lambda x:x.median())\n",
    "# # date4_feature['date4_up_flow_median'] = x.values\n",
    "# \n",
    "# #总流量\n",
    "# date4['flow'] = date4['down_flow'] + date4['up_flow']\n",
    "# gp = date4.groupby('uid')['flow']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date4_feature['date4_flow_sum'] = x.values\n",
    "# \n",
    "# gp = date4.groupby('uid')['date']\n",
    "# y = gp.apply(lambda x:len(set(x)))\n",
    "# date4_feature['date4_flow_perday_mean'] = date4_feature['date4_flow_sum'] / y.values\n",
    "# \n",
    "# gp = date4.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date4_feature['date4_flow_sum_percnt'] = date4_feature['date4_flow_sum'] / x.values \n",
    "# \n",
    "# gp = date4.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date4_feature['date4_dura_sum_percnt'] = date4_feature['date4_visit_dura_sum'] / x.values \n",
    "# \n",
    "# #APP/网站访问天数\n",
    "# gp = date4.groupby(['uid','wa_type'])['date']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# date4_feature['date4_type0_date_mean'] = x['0']\n",
    "# date4_feature['date4_type4_date_mean'] = x['4']\n",
    "# \n",
    "# gp = date4.groupby(['uid','wa_type'])['date']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# date4_feature['date4_type0_date_cnt'] = x['0']\n",
    "# date4_feature['date4_type4_date_cnt'] = x['4']\n",
    "# \n",
    "# #APP/网站访问总次数\n",
    "# \n",
    "# gp = date4.groupby(['uid','wa_type'])['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# date4_feature['date4_type0_visitcnt_mean'] = x['0']\n",
    "# date4_feature['date4_type4_visitcnt_mean'] = x['4']\n",
    "# \n",
    "# #APP/网站上载量\n",
    "# gp = date4.groupby(['uid','wa_type'])['up_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# date4_feature['date4_type0_upflow_mean'] = x['0']\n",
    "# date4_feature['date4_type4_upflow_mean'] = x['4']\n",
    "# #APP/网站下载量\n",
    "# gp = date4.groupby(['uid','wa_type'])['down_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# date4_feature['date4_type0_downflow_mean'] = x['0']\n",
    "# date4_feature['date4_type4_downflow_mean'] = x['4']\n",
    "# gp = date4.groupby(['uid','wa_type'])['flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# date4_feature['date4_type0_flow_mean'] = x['0']\n",
    "# date4_feature['date4_type4_flow_mean'] = x['4']\n",
    "# #APP/网站访问平均时长\n",
    "# gp = date4.groupby(['uid','wa_type'])['visit_dura']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# date4_feature['date4_type0_dura_mean'] = x['0']\n",
    "# date4_feature['date4_type4_dura_mean'] = x['4']\n",
    "# \n",
    "# gp=date4.groupby('uid')['wa_name']\n",
    "# x=gp.apply(lambda x:len(set(x)))\n",
    "# date4_feature['date4_name_count_uinque']=x.values\n",
    "# #APP/网站分别访问了多少种\n",
    "# gp = date4.groupby(['uid','wa_type'])['wa_name']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','4']\n",
    "# date4_feature['date4_type0_name_unique'] = x['0']\n",
    "# date4_feature['date4_type4_name_unique'] = x['4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature = train_feature.merge(date4_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# train_feature = train_feature.fillna(0)\n",
    "# test_feature = test_feature.merge(date4_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date5 = pd.DataFrame()\n",
    "# date5 = wa[wa['date']>36]\n",
    "# date5 = date5[date5['date']<=45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date5_feature = pd.DataFrame()\n",
    "# #上网总天数\n",
    "# gp = date5.groupby('uid')['date']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# date5_feature['uid'] = x.index\n",
    "# date5_feature['date5_visit_date_cnt'] = x.values\n",
    "# #访问次数\n",
    "# # gp = date5.groupby('uid')['visit_cnt']\n",
    "# # x = gp.apply(lambda x:x.sum())\n",
    "# # date5_feature['date5_visit_cnt_sum'] = x.values\n",
    "# # \n",
    "# # gp = date5.groupby('uid')['visit_cnt']\n",
    "# # x = gp.apply(lambda x:x.max())\n",
    "# # date5_feature['date5_visit_cnt_max'] = x.values\n",
    "# # \n",
    "# # gp = date5.groupby('uid')['visit_cnt']\n",
    "# # x = gp.apply(lambda x:x.std())\n",
    "# # date5_feature['date5_visit_cnt_std'] = x.values\n",
    "# # \n",
    "# # gp = date5.groupby('uid')['visit_cnt']\n",
    "# # x = gp.apply(lambda x:x.median())\n",
    "# # date5_feature['date5_visit_cnt_median'] = x.values\n",
    "# # \n",
    "# gp = date5.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date5_feature['date5_visit_cnt_mean'] = x.values\n",
    "# #访问时长\n",
    "# # \n",
    "# gp = date5.groupby('uid')['visit_dura']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date5_feature['date5_visit_dura_sum'] = x.values\n",
    "# # \n",
    "# # gp = date5.groupby('uid')['visit_dura']\n",
    "# # x = gp.apply(lambda x:x.max())\n",
    "# # date5_feature['date5_visit_dura_max'] = x.values\n",
    "# # \n",
    "# # gp = date5.groupby('uid')['visit_dura']\n",
    "# # x = gp.apply(lambda x:x.std())\n",
    "# # date5_feature['date5_visit_dura_std'] = x.values\n",
    "# # \n",
    "# # gp = date5.groupby('uid')['visit_dura']\n",
    "# # x = gp.apply(lambda x:x.median())\n",
    "# # date5_feature['date5_visit_dura_median'] = x.values\n",
    "# \n",
    "# gp = date5.groupby('uid')['visit_dura']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date5_feature['date5_visit_dura_mean'] = x.values\n",
    "# \n",
    "# gp = date5.groupby('uid')['down_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date5_feature['date5_down_flow_mean'] = x.values\n",
    "# \n",
    "# # gp = date5.groupby('uid')['down_flow']\n",
    "# # x = gp.apply(lambda x:x.sum())\n",
    "# # date5_feature['date5_down_flow_sum'] = x.values\n",
    "# # \n",
    "# # gp = date5.groupby('uid')['down_flow']\n",
    "# # x = gp.apply(lambda x:x.max())\n",
    "# # date5_feature['date5_down_flow_max'] = x.values\n",
    "# # \n",
    "# # gp = date5.groupby('uid')['down_flow']\n",
    "# # x = gp.apply(lambda x:x.median())\n",
    "# # date5_feature['date5_down_flow_median'] = x.values\n",
    "# # \n",
    "# # gp = date5.groupby('uid')['down_flow']\n",
    "# # x = gp.apply(lambda x:x.std())\n",
    "# # date5_feature['date5_down_flow_std'] = x.values\n",
    "# \n",
    "# gp = date5.groupby('uid')['up_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# date5_feature['date5_up_flow_mean'] = x.values\n",
    "# \n",
    "# # gp = date5.groupby('uid')['up_flow']\n",
    "# # x = gp.apply(lambda x:x.sum())\n",
    "# # date5_feature['date5_up_flow_sum'] = x.values\n",
    "# # \n",
    "# # gp = date5.groupby('uid')['up_flow']\n",
    "# # x = gp.apply(lambda x:x.max())\n",
    "# # date5_feature['date5_up_flow_max'] = x.values\n",
    "# # \n",
    "# # gp = date5.groupby('uid')['up_flow']\n",
    "# # x = gp.apply(lambda x:x.std())\n",
    "# # date5_feature['date5_up_flow_std'] = x.values\n",
    "# # \n",
    "# # gp = date5.groupby('uid')['up_flow']\n",
    "# # x = gp.apply(lambda x:x.median())\n",
    "# # date5_feature['date5_up_flow_median'] = x.values\n",
    "# \n",
    "# #总流量\n",
    "# date5['flow'] = date5['down_flow'] + date5['up_flow']\n",
    "# gp = date5.groupby('uid')['flow']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date5_feature['date5_flow_sum'] = x.values\n",
    "# \n",
    "# gp = date5.groupby('uid')['date']\n",
    "# y = gp.apply(lambda x:len(set(x)))\n",
    "# date5_feature['date5_flow_perday_mean'] = date5_feature['date5_flow_sum'] / y.values\n",
    "# \n",
    "# gp = date5.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date5_feature['date5_flow_sum_percnt'] = date5_feature['date5_flow_sum'] / x.values \n",
    "# \n",
    "# gp = date5.groupby('uid')['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.sum())\n",
    "# date5_feature['date5_dura_sum_percnt'] = date5_feature['date5_visit_dura_sum'] / x.values \n",
    "# \n",
    "# #APP/网站访问天数\n",
    "# gp = date5.groupby(['uid','wa_type'])['date']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# date5_feature['date5_type0_date_mean'] = x['0']\n",
    "# date5_feature['date5_type5_date_mean'] = x['5']\n",
    "# \n",
    "# gp = date5.groupby(['uid','wa_type'])['date']\n",
    "# x = gp.apply(lambda x:x.count())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# date5_feature['date5_type0_date_cnt'] = x['0']\n",
    "# date5_feature['date5_type5_date_cnt'] = x['5']\n",
    "# \n",
    "# #APP/网站访问总次数\n",
    "# \n",
    "# gp = date5.groupby(['uid','wa_type'])['visit_cnt']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# date5_feature['date5_type0_visitcnt_mean'] = x['0']\n",
    "# date5_feature['date5_type5_visitcnt_mean'] = x['5']\n",
    "# \n",
    "# #APP/网站上载量\n",
    "# gp = date5.groupby(['uid','wa_type'])['up_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# date5_feature['date5_type0_upflow_mean'] = x['0']\n",
    "# date5_feature['date5_type5_upflow_mean'] = x['5']\n",
    "# #APP/网站下载量\n",
    "# gp = date5.groupby(['uid','wa_type'])['down_flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# date5_feature['date5_type0_downflow_mean'] = x['0']\n",
    "# date5_feature['date5_type5_downflow_mean'] = x['5']\n",
    "# gp = date5.groupby(['uid','wa_type'])['flow']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# date5_feature['date5_type0_flow_mean'] = x['0']\n",
    "# date5_feature['date5_type5_flow_mean'] = x['5']\n",
    "# #APP/网站访问平均时长\n",
    "# gp = date5.groupby(['uid','wa_type'])['visit_dura']\n",
    "# x = gp.apply(lambda x:x.mean())\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# date5_feature['date5_type0_dura_mean'] = x['0']\n",
    "# date5_feature['date5_type5_dura_mean'] = x['5']\n",
    "# \n",
    "# gp=date5.groupby('uid')['wa_name']\n",
    "# x=gp.apply(lambda x:len(set(x)))\n",
    "# date5_feature['date5_name_count_uinque']=x.values\n",
    "# #APP/网站分别访问了多少种\n",
    "# gp = date5.groupby(['uid','wa_type'])['wa_name']\n",
    "# x = gp.apply(lambda x:len(set(x)))\n",
    "# x = x.unstack(fill_value=0).reset_index(drop=True)\n",
    "# x.columns = ['0','5']\n",
    "# date5_feature['date5_type0_name_unique'] = x['0']\n",
    "# date5_feature['date5_type5_name_unique'] = x['5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature = train_feature.merge(date5_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# train_feature = train_feature.fillna(0)\n",
    "# test_feature = test_feature.merge(date5_feature,on='uid',how='left').reset_index(drop=True)\n",
    "# test_feature = test_feature.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature.to_csv('train_feature_v1.csv',index=None)\n",
    "test_feature.to_csv('test_feature_b_v1.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4999 entries, 0 to 4998\nColumns: 229 entries, uid to wa_type1_down_perday\ndtypes: float64(225), int64(3), object(1)\nmemory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_feature.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
